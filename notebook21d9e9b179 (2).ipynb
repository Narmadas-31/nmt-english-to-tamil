{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U transformers datasets peft accelerate bitsandbytes evaluate sacrebleu sacremoses --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:23:13.886460Z","iopub.execute_input":"2025-08-09T09:23:13.887001Z","iopub.status.idle":"2025-08-09T09:23:29.321420Z","shell.execute_reply.started":"2025-08-09T09:23:13.886979Z","shell.execute_reply":"2025-08-09T09:23:29.320694Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.9/503.9 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"ai4bharat/samanantar\", \"ta\")\ndataset[\"train\"] = dataset[\"train\"].select(range(50000))  # first 50k examples\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:24:35.427311Z","iopub.execute_input":"2025-08-09T09:24:35.427973Z","iopub.status.idle":"2025-08-09T09:24:47.425417Z","shell.execute_reply.started":"2025-08-09T09:24:35.427943Z","shell.execute_reply":"2025-08-09T09:24:47.424629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3b5c88ade26436f8f62e36a3eaa4871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00004.parquet:   0%|          | 0.00/189M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9874511d27dd469c82d36c996075f4fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00004.parquet:   0%|          | 0.00/189M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00eafdd6abd44b0dbb1f39785f399085"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00004.parquet:   0%|          | 0.00/188M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5968be4320146baabd49f88205c3cb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00004.parquet:   0%|          | 0.00/188M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83cba963447549da92a313d116092e88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5264867 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41c7137f467945949caf7ec571e2a9d7"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer\nmodel_name = \"Helsinki-NLP/opus-mt-en-dra\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\ndef preprocess_function(examples):\n    inputs = [\">>tam<< \" + src for src in examples[\"src\"]]\n    targets = examples[\"tgt\"]\n\n    model_inputs = tokenizer(\n        inputs, max_length=128, padding=\"max_length\", truncation=True\n    )\n    labels = tokenizer(\n        text_target=targets, max_length=128, padding=\"max_length\", truncation=True\n    )\n    model_inputs[\"labels\"] = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label_seq]\n        for label_seq in labels[\"input_ids\"]\n    ]\n    return model_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:25:23.369527Z","iopub.execute_input":"2025-08-09T09:25:23.370820Z","iopub.status.idle":"2025-08-09T09:25:34.245895Z","shell.execute_reply.started":"2025-08-09T09:25:23.370787Z","shell.execute_reply":"2025-08-09T09:25:34.245046Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4f94db2855402c82ff478e0bcb6507"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b47a21cf8cf4eb09cfd43bbdb514b5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/818k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"537a8b21b6ce4f81adad14d501d3c95b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/1.17M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e282e44ccb425eaa1d38267b4d0d7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42d62e20e34f4c3190587563a36e2126"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"tokenized_dataset = dataset.map(preprocess_function, batched=True)\nsplit_dataset = tokenized_dataset[\"train\"].train_test_split(test_size=0.1)\ntrain_dataset = split_dataset[\"train\"]\nval_dataset = split_dataset[\"test\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:25:58.987534Z","iopub.execute_input":"2025-08-09T09:25:58.988266Z","iopub.status.idle":"2025-08-09T09:26:39.044815Z","shell.execute_reply.started":"2025-08-09T09:25:58.988237Z","shell.execute_reply":"2025-08-09T09:26:39.043998Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"741bb5c46ccd495c882d1757ab3b4401"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\nfrom peft import LoraConfig, get_peft_model\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQ_2_SEQ_LM\"\n)\nmodel = get_peft_model(model, lora_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:27:01.202686Z","iopub.execute_input":"2025-08-09T09:27:01.203225Z","iopub.status.idle":"2025-08-09T09:27:20.578519Z","shell.execute_reply.started":"2025-08-09T09:27:01.203201Z","shell.execute_reply":"2025-08-09T09:27:20.577847Z"}},"outputs":[{"name":"stderr","text":"2025-08-09 09:27:04.130007: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754731624.342826     138 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754731624.404006     138 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b88a79aea2064a94a529a4e4d6399704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efb65f5aadf543b084e9c032161b815c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d725a509547f4040a87c31e9e4c384fd"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=3e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=3,\n    predict_with_generate=True,\n    report_to=\"tensorboard\",   # \"none\" if you don’t want logs\n    logging_dir=\"./logs\",\n    fp16=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:28:50.312291Z","iopub.execute_input":"2025-08-09T09:28:50.312741Z","iopub.status.idle":"2025-08-09T09:28:50.342546Z","shell.execute_reply.started":"2025-08-09T09:28:50.312709Z","shell.execute_reply":"2025-08-09T09:28:50.341723Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    processing_class=tokenizer\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:29:05.812168Z","iopub.execute_input":"2025-08-09T09:29:05.812478Z","iopub.status.idle":"2025-08-09T09:56:19.948406Z","shell.execute_reply.started":"2025-08-09T09:29:05.812446Z","shell.execute_reply":"2025-08-09T09:56:19.947639Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='16875' max='16875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [16875/16875 27:11, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.442200</td>\n      <td>3.185384</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.331000</td>\n      <td>3.115635</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.319800</td>\n      <td>3.093492</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=16875, training_loss=3.4654998191550925, metrics={'train_runtime': 1632.0799, 'train_samples_per_second': 82.717, 'train_steps_per_second': 10.34, 'total_flos': 4637432217600000.0, 'train_loss': 3.4654998191550925, 'epoch': 3.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir ./logs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:56:54.927277Z","iopub.execute_input":"2025-08-09T09:56:54.927566Z","iopub.status.idle":"2025-08-09T09:57:00.965983Z","shell.execute_reply.started":"2025-08-09T09:56:54.927546Z","shell.execute_reply":"2025-08-09T09:57:00.965102Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    "},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import os\nprint(os.listdir(\"./logs\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T09:58:31.907545Z","iopub.execute_input":"2025-08-09T09:58:31.907865Z","iopub.status.idle":"2025-08-09T09:58:31.912319Z","shell.execute_reply.started":"2025-08-09T09:58:31.907842Z","shell.execute_reply":"2025-08-09T09:58:31.911744Z"}},"outputs":[{"name":"stdout","text":"['events.out.tfevents.1754731747.749abd39bcc6.138.0']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/checkpoint\")\ntokenizer.save_pretrained(\"/kaggle/working/checkpoint\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T10:00:13.302429Z","iopub.execute_input":"2025-08-09T10:00:13.302989Z","iopub.status.idle":"2025-08-09T10:00:13.618597Z","shell.execute_reply.started":"2025-08-09T10:00:13.302966Z","shell.execute_reply":"2025-08-09T10:00:13.617823Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/checkpoint/tokenizer_config.json',\n '/kaggle/working/checkpoint/special_tokens_map.json',\n '/kaggle/working/checkpoint/vocab.json',\n '/kaggle/working/checkpoint/source.spm',\n '/kaggle/working/checkpoint/target.spm',\n '/kaggle/working/checkpoint/added_tokens.json')"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"!zip -r checkpoint.zip /kaggle/working/checkpoint\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T10:06:55.825624Z","iopub.execute_input":"2025-08-09T10:06:55.825894Z","iopub.status.idle":"2025-08-09T10:06:56.423442Z","shell.execute_reply.started":"2025-08-09T10:06:55.825872Z","shell.execute_reply":"2025-08-09T10:06:56.422405Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/checkpoint/ (stored 0%)\n  adding: kaggle/working/checkpoint/adapter_config.json (deflated 56%)\n  adding: kaggle/working/checkpoint/README.md (deflated 66%)\n  adding: kaggle/working/checkpoint/special_tokens_map.json (deflated 35%)\n  adding: kaggle/working/checkpoint/source.spm (deflated 51%)\n  adding: kaggle/working/checkpoint/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/checkpoint/target.spm (deflated 60%)\n  adding: kaggle/working/checkpoint/vocab.json (deflated 76%)\n  adding: kaggle/working/checkpoint/tokenizer_config.json (deflated 68%)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ncheckpoint_dir = \"/kaggle/working/checkpoint\"\n\n# Load tokenizer and model from checkpoint folder\ntokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_dir)\n\n# Example English sentences to translate\nsentences = [\n    \"Hello, how are you?\",\n    \"This is a test sentence.\",\n    \"I am fine tuning a translation model on Kaggle.\"\n]\n\ninputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n\n# Generate translations\noutputs = model.generate(**inputs, max_length=128)\ntranslations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\n# Print translated sentences\nfor src, tgt in zip(sentences, translations):\n    print(f\"Input: {src}\")\n    print(f\"Translation: {tgt}\")\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T10:22:39.985161Z","iopub.execute_input":"2025-08-09T10:22:39.985846Z","iopub.status.idle":"2025-08-09T10:22:42.769281Z","shell.execute_reply.started":"2025-08-09T10:22:39.985815Z","shell.execute_reply":"2025-08-09T10:22:42.768204Z"}},"outputs":[{"name":"stdout","text":"Input: Hello, how are you?\nTranslation: ஹலோ, ఎలా ఉన్నావు?\n\nInput: This is a test sentence.\nTranslation: இது ஒரு சோதனைத் தீர்ப்பு.\n\nInput: I am fine tuning a translation model on Kaggle.\nTranslation: Kaggle on Windown Cagle ನ ಭಾಷಾಂತರ ನಮೂನೆಯನ್ನು ಸರಿಯಾಗಿ ಅರ್ಥನಿರೂಪಿಸುತ್ತಿದ್ದೇನೆ.\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ncheckpoint_dir = \"/kaggle/working/checkpoint\"\n\n# Load tokenizer and model checkpoint\ntokenizer = AutoTokenizer.from_pretrained(checkpoint_dir)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_dir)\n\n# Your English sentences with appropriate target language prefix\nsentences = [\n    \"Hello, how are you?\",\n    \"This is a test sentence.\",\n    \"I am fine tuning a translation model on Kaggle.\"\n]\n\n# Add the Tamil language token prefix as used during training\ninputs = tokenizer([\">>tam<< \" + s for s in sentences], return_tensors=\"pt\", padding=True, truncation=True)\n\n# Generate translations with model\noutputs = model.generate(**inputs, max_length=128)\n\n# Decode the outputs skipping special tokens\ntranslations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n\n# Print final translations (all should be in Tamil)\nfor src, tgt in zip(sentences, translations):\n    print(f\"Input: {src}\")\n    print(f\"Translation: {tgt}\")\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T10:24:22.135123Z","iopub.execute_input":"2025-08-09T10:24:22.135468Z","iopub.status.idle":"2025-08-09T10:24:24.137853Z","shell.execute_reply.started":"2025-08-09T10:24:22.135446Z","shell.execute_reply":"2025-08-09T10:24:24.137029Z"}},"outputs":[{"name":"stdout","text":"Input: Hello, how are you?\nTranslation: ஹலோ, எப்படி இருக்கிறாய்?\n\nInput: This is a test sentence.\nTranslation: இது ஒரு சோதனைத் தீர்ப்பு.\n\nInput: I am fine tuning a translation model on Kaggle.\nTranslation: கக்லேயில் ஒரு மொழிபெயர்ப்பு மாதிரியை நடித்துக்கொண்டு வருகிறேன்.\n\n","output_type":"stream"}],"execution_count":15}]}